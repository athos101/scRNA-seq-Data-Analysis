{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363766e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/usuario/.local/lib/python3.9/site-packages/tqdm-4.66.2-py3.9.egg/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Loading libraries\n",
    "\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import scvi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.stats import median_abs_deviation\n",
    "import scanpy as sc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a55026",
   "metadata": {},
   "source": [
    "## Gathering single-cell sequencing files (only if necessary)\n",
    "This code just gather the matrix.mtx, the barcodes.tsv (could be cellid.tsv) and the gene.tsv (could be features.tsv) files into one anndata object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6efcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p031n', 'p027n', 'p018n', 'p032n', 'p034n', 'p030t', 'p033t', 'p027t', 'p023t', 'p030n', 'p018t', 'p033n', 'p032t', 'p029n', 'p034t', 'p031t', 'p024t', 'p019t', 'p028n', 'p019n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/.local/lib/python3.9/site-packages/anndata-0.10.5.post1-py3.9.egg/anndata/_core/anndata.py:1906: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "# Dir to the samples\n",
    "sample_path = '../sc_data_directory'\n",
    "# Folders between the sample name and the files (if doesn't exist, put '')\n",
    "middle_path = 'filtered_feature_bc_matrix'\n",
    "\n",
    "sample_names = []\n",
    "for foldername in os.listdir(sample_path):\n",
    "    if os.path.isdir(os.path.join(sample_path, foldername)):\n",
    "        sample_names.append(foldername)\n",
    "print(sample_names)\n",
    "# For each sample, read the directory to a list of samples.\n",
    "        \n",
    "sample_list = []\n",
    "\n",
    "for name in sample_names:\n",
    "    # Getting anndata (transposed to obs X vars)\n",
    "    path = f'{sample_path}/{name}/{middle_path}/matrix.mtx.gz'\n",
    "    sample = sc.read(path, cache=True).T\n",
    "    \n",
    "    # Getting obs\n",
    "    path = f'{sample_path}/{name}/{middle_path}/barcodes.tsv.gz'\n",
    "    obs = pd.read_csv(path, sep='\\t', header=None, index_col=0)\n",
    "    obs.index.name = 'barcode'\n",
    "    sample.obs = obs\n",
    "    \n",
    "    # Adding metadata (IN MY CASE, THE INFORMATION OF PATIENT AND CONDITION WAS IN THE FILE NAME)\n",
    "    sample.obs['Patient'] = name\n",
    "    sample.obs['Condition'] = name[-1].upper()\n",
    "    \n",
    "    # Getting vars\n",
    "    path = f\"{sample_path}/{name}/{middle_path}/features.tsv.gz\"\n",
    "    var = pd.read_table(path, sep='\\t', header=None, index_col=1)\n",
    "    var.index.name = 'genes'\n",
    "    sample.var = var\n",
    "    sample.var_names_make_unique(join=\"-\")\n",
    "    \n",
    "    sample_list.append(sample)\n",
    "\n",
    "adata = ad.concat(sample_list)\n",
    "adata.obs_names_make_unique()\n",
    "del sample_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6996c",
   "metadata": {},
   "source": [
    "## HVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff2f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['counts']=adata.X.copy()\n",
    "sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=5000, \n",
    "                            layer='counts',subset=True, batch_key='Patient')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f2427",
   "metadata": {},
   "source": [
    "## Doublet removal with SOLO (SCVi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/miniconda3/envs/atlas_protocol/lib/python3.9/abc.py:119: FutureWarning: SparseDataset is deprecated and will be removed in late 2024. It has been replaced by the public classes CSRDataset and CSCDataset.\n",
      "\n",
      "For instance checks, use `isinstance(X, (anndata.experimental.CSRDataset, anndata.experimental.CSCDataset))` instead.\n",
      "\n",
      "For creation, use `anndata.experimental.sparse_dataset(X)` instead.\n",
      "\n",
      "  return _abc_instancecheck(cls, instance)\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/miniconda3/envs/atlas_protocol/lib/python3.9/abc.py:119: FutureWarning: SparseDataset is deprecated and will be removed in late 2024. It has been replaced by the public classes CSRDataset and CSCDataset.\n",
      "\n",
      "For instance checks, use `isinstance(X, (anndata.experimental.CSRDataset, anndata.experimental.CSCDataset))` instead.\n",
      "\n",
      "For creation, use `anndata.experimental.sparse_dataset(X)` instead.\n",
      "\n",
      "  return _abc_instancecheck(cls, instance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100:  94%|█████████▍| 94/100 [05:14<00:19,  3.30s/it, loss=1.15e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/miniconda3/envs/atlas_protocol/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    }
   ],
   "source": [
    "scvi.model.SCVI.setup_anndata(adata, layer='counts')\n",
    "model = scvi.model.SCVI(adata)\n",
    "model.train(max_epochs=100)\n",
    "\n",
    "solo = scvi.external.SOLO.from_scvi_model(model)\n",
    "solo.train()\n",
    "\n",
    "solo_df = solo.predict()\n",
    "solo_df\n",
    "cell_mapper = dict(zip(solo_df.index, solo_df.prediction))\n",
    "adata.obs['doublet_pred'] = adata.obs.index.map(cell_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b105e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata[~adata.obs.doublet_pred].shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6ed30",
   "metadata": {},
   "source": [
    "## QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['mt'] = adata.var_names.str.startswith('MT-')\n",
    "adata.var['ribo'] = adata.var_names.str.startswith(('RPS','RPL'))\n",
    "adata.var['hb'] = adata.var_names.str.startswith((\"^HB[^(P)]\"))\n",
    "\n",
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, qc_vars=['mt','ribo','hb'], inplace=True, percent_top=[20], log1p=True\n",
    ")\n",
    "\n",
    "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_ribo',\n",
    "                     'pct_counts_hb', 'pct_counts_mt'], jitter=0.4, multi_panel=True)\n",
    "\n",
    "def is_outlier(adata, metric: str, nmads: int):\n",
    "    M = adata.obs[metric]\n",
    "    outlier = (M < np.median(M) - nmads * median_abs_deviation(M)) | (\n",
    "        np.median(M) + nmads * median_abs_deviation(M) < M\n",
    "    )\n",
    "    return outlier\n",
    "\n",
    "adata.obs[\"outlier\"] = (\n",
    "    is_outlier(adata, \"log1p_total_counts\", 5)\n",
    "    | is_outlier(adata, \"log1p_n_genes_by_counts\", 5)\n",
    "    | is_outlier(adata, \"pct_counts_in_top_20_genes\", 5)\n",
    ")\n",
    "\n",
    "adata.obs[\"mt_outlier\"] = is_outlier(adata, \"pct_counts_mt\", 3) | (\n",
    "    adata.obs[\"pct_counts_mt\"] > 8\n",
    ")\n",
    "\n",
    "adata = adata[(~adata.obs.outlier) & (~adata.obs.mt_outlier)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc9c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(\"../h5ad_Datasets/atlas_v2_raw.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b3be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t2.0\n",
      "  (0, 5)\t1.0\n",
      "  (1, 3)\t1.0\n",
      "  (2, 7)\t2.0\n",
      "  (3, 7)\t2.0\n",
      "  (3, 3)\t2.0\n",
      "  (4, 7)\t1.0\n",
      "  (5, 8)\t2.0\n",
      "  (6, 7)\t1.0\n",
      "  (8, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(adata.X[0:10,0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a59884",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf60c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "#adata.raw = adata\n",
    "\n",
    "#sc.pl.highest_expr_genes(adata, n_top=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62360b98",
   "metadata": {},
   "source": [
    "## scVI Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c089cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/miniconda3/envs/atlas_protocol/lib/python3.9/abc.py:119: FutureWarning: SparseDataset is deprecated and will be removed in late 2024. It has been replaced by the public classes CSRDataset and CSCDataset.\n",
      "\n",
      "For instance checks, use `isinstance(X, (anndata.experimental.CSRDataset, anndata.experimental.CSCDataset))` instead.\n",
      "\n",
      "For creation, use `anndata.experimental.sparse_dataset(X)` instead.\n",
      "\n",
      "  return _abc_instancecheck(cls, instance)\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/home/usuario/miniconda3/envs/atlas_protocol/lib/python3.9/site-packages/scvi/data/fields/_layer_field.py:90: UserWarning: adata.X does not contain unnormalized count data. Are you sure this is what you want?\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/miniconda3/envs/atlas_protocol/lib/python3.9/abc.py:119: FutureWarning: SparseDataset is deprecated and will be removed in late 2024. It has been replaced by the public classes CSRDataset and CSCDataset.\n",
      "\n",
      "For instance checks, use `isinstance(X, (anndata.experimental.CSRDataset, anndata.experimental.CSCDataset))` instead.\n",
      "\n",
      "For creation, use `anndata.experimental.sparse_dataset(X)` instead.\n",
      "\n",
      "  return _abc_instancecheck(cls, instance)\n",
      "/home/usuario/miniconda3/envs/atlas_protocol/lib/python3.9/site-packages/scvi/distributions/_negative_binomial.py:476: UserWarning: The value argument must be within the support of the distribution\n",
      "  warnings.warn(\n",
      "/home/usuario/miniconda3/envs/atlas_protocol/lib/python3.9/site-packages/scvi/distributions/_negative_binomial.py:476: UserWarning: The value argument must be within the support of the distribution\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/16:   6%|▋         | 1/16 [00:38<09:36, 38.44s/it, loss=4.54e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/miniconda3/envs/atlas_protocol/lib/python3.9/site-packages/scvi/distributions/_negative_binomial.py:476: UserWarning: The value argument must be within the support of the distribution\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/16: 100%|██████████| 16/16 [10:03<00:00, 37.67s/it, loss=4.44e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/16: 100%|██████████| 16/16 [10:03<00:00, 37.70s/it, loss=4.44e+03, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "scvi.model.SCVI.setup_anndata(adata, batch_key='patient')\n",
    "\n",
    "arches_params = dict(\n",
    "    use_layer_norm='both',\n",
    "    use_batch_norm='none',\n",
    "    encode_covariates=True,\n",
    "    dropout_rate=0.2,\n",
    "    n_layers=2,\n",
    ")\n",
    "\n",
    "vae = scvi.model.SCVI(adata, **arches_params)\n",
    "vae.train()\n",
    "\n",
    "adata.obsm[\"X_scVI\"] = vae.get_latent_representation() #dimensional reduction\n",
    "adata.layers['scvi_normalized'] = vae.get_normalized_expression(library_size = 1e4)\n",
    "sc.pp.neighbors(adata, use_rep=\"X_scVI\")\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6cafc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(\"adata_processed_genes18k.h5ad\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
